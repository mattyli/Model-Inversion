{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "30f6cbe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 1. Load the full Identity file\n",
    "df = pd.read_csv('identity_CelebA.txt', sep='\\s+', header=None, names=['image_path', 'id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f134d59c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Identities: 10177\n",
      "Filtered Identities (>=5 images): 9343\n",
      "Images Dropped: 2311\n"
     ]
    }
   ],
   "source": [
    "id_counts = df['id'].value_counts()\n",
    "valid_ids = id_counts[id_counts >= 5].index\n",
    "df_filtered = df[df['id'].isin(valid_ids)]\n",
    "\n",
    "print(f\"Original Identities: {len(df['id'].unique())}\")\n",
    "print(f\"Filtered Identities (>=5 images): {len(valid_ids)}\")\n",
    "print(f\"Images Dropped: {len(df) - len(df_filtered)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "84d0af29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total Victim Images: 10815\n",
      "Total Attacker Images: 189473\n",
      "\n",
      "--- Splits Saved ---\n",
      "1. victim_train.csv: 6921 images\n",
      "2. victim_val.csv:   1731 images\n",
      "3. victim_test.csv:  2163 images\n",
      "4. attacker_data.csv:189473 images\n"
     ]
    }
   ],
   "source": [
    "unique_valid_ids = df_filtered['id'].unique()\n",
    "victim_ids = np.random.choice(unique_valid_ids, size=500, replace=False)\n",
    "\n",
    "# Create the two massive pools of data\n",
    "victim_pool_df = df_filtered[df_filtered['id'].isin(victim_ids)]\n",
    "attacker_pool_df = df_filtered[~df_filtered['id'].isin(victim_ids)]\n",
    "\n",
    "print(f\"\\nTotal Victim Images: {len(victim_pool_df)}\")\n",
    "print(f\"Total Attacker Images: {len(attacker_pool_df)}\")\n",
    "\n",
    "# 4. Inner-Split: Break Victim Pool into Train, Val, Test\n",
    "# Step A: Split off the TEST set (20%)\n",
    "# Stratify ensures every ID appears in the test set\n",
    "victim_dev, victim_test = train_test_split(\n",
    "    victim_pool_df, \n",
    "    test_size=0.2, \n",
    "    stratify=victim_pool_df['id'], \n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Step B: Split the remaining \"Dev\" set into TRAIN and VAL (80/20 of the remaining)\n",
    "victim_train, victim_val = train_test_split(\n",
    "    victim_dev, \n",
    "    test_size=0.2, \n",
    "    stratify=victim_dev['id'], \n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# 5. Save to CSVs\n",
    "victim_train.to_csv(\"victim_train.csv\", index=False)\n",
    "victim_val.to_csv(\"victim_val.csv\", index=False)\n",
    "victim_test.to_csv(\"victim_test.csv\", index=False)\n",
    "attacker_pool_df.to_csv(\"attacker_data.csv\", index=False)\n",
    "\n",
    "print(\"\\n--- Splits Saved ---\")\n",
    "print(f\"1. victim_train.csv: {len(victim_train)} images\")\n",
    "print(f\"2. victim_val.csv:   {len(victim_val)} images\")\n",
    "print(f\"3. victim_test.csv:  {len(victim_test)} images\")\n",
    "print(f\"4. attacker_data.csv:{len(attacker_pool_df)} images\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm-dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
